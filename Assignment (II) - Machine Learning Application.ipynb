{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2269e342",
   "metadata": {
    "id": "2269e342"
   },
   "source": [
    "# <center>DSAI2201 - Assignment II</center> \n",
    "## <center>Due: Novemver 25th, 2023 at 10:00 PM </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecffbbfc",
   "metadata": {
    "id": "ecffbbfc"
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menu bar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menu bar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure that in addition to the code, you provide written answers for all questions of the assignment. \n",
    "\n",
    "Below, please fill in your name and collaborators:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15241982-2631-4d96-b9f1-1daefbe0d81c",
   "metadata": {
    "id": "e13716c6"
   },
   "source": [
    "- NAME: Almabrouk Ben-Omran\n",
    "- STUDENT_ID: 60104920\n",
    "- SECTION: 4\n",
    "- INSTRUCTOR: Dr. Somaiyeh Mahmoudzadeh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27016452",
   "metadata": {
    "id": "27016452"
   },
   "source": [
    "# Assignment 2 - Machine Learning Models for Prediction\n",
    "**(30 points total)**\n",
    "\n",
    "In Assignments 1 & 2 we will go through the entire journey of a small data science project. \n",
    "* In **Assignment 1**, we have explored the data, cleaned up the data, modified features, and created new ones. \n",
    "* In **Assignment 2**, we will apply supervised machine learning models for classification and regression, evaluate its perofrmance, and identify the best models to solve the following problems: \n",
    "\n",
    "    * The **classification problem** is: given a train dataset of passengers who survived or did not survive the Titanic disaster, build a model which can determine based on a given test dataset not containing the survival information, if these passengers in the test dataset survived or not. \n",
    "\n",
    "    * The **regression problem** is: predict the fare of a certain passenger based on known relevant feature values.\n",
    "\n",
    "* You will use the same train.csv data which you have prepared in Assignment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a11a",
   "metadata": {
    "id": "2e88a11a"
   },
   "source": [
    "**Question 1. (Data preparation)**  _(5 points)_\n",
    "* List the relevant features which you will use for classification and explain your answer (*a relevant feature is a feature that can have an impact on the chance of survival of the passenger*).\n",
    "* List the relevant features which you will use for regression and explain your answer (*a relevant feature is a feature that can have an impact on the prediction of the fare of a certain passenger*).\n",
    "* Divide your data into a training set (70%) and a testing set (30%). All models will be trained and tested on the same splits.\n",
    "    \n",
    "\n",
    "**Question 2. (Classification models)**  _(10 points)_\n",
    "* Train three different classification models of your choice using the training set. Explain the rationale behind selecting each of these three algorithms. You may refer to the following guidlines for model selection: \n",
    "    * Diagram from scikit-learn: https://scikit-learn.org/stable/tutorial/machine_learning_map/\n",
    "    * Models comparison table: https://docs.google.com/spreadsheets/d/16i47Wmjpj8k-mFRk-NnXXU5tmSQz8h37YxluDV8Zy9U/edit#gid=0\n",
    "\n",
    "**Question 3. (Evaluation of classification models)**  _(5 points)_\n",
    "* Evaluate the performance of your three classification models on the testing set using the following metrics: accuracy, area under the curve (AUC), precision, and recall.\n",
    "* Based on the models evaluation results, what is the best model and why?\n",
    "\n",
    "\n",
    "**Question 4. (Regression models)**  _(5 points)_\n",
    "* Train two different regression models of your choice using the training set. Explain the rationale behind selecting each of these two algorithms. \n",
    "\n",
    "**Question 5. (Evaluation of regression models)**  _(3 points)_\n",
    "* Evaluate the performance of your two regression models on the testing set using the following metrics: mean absolute error,mean squared error, and R-square.\n",
    "* Based on the models evaluation results, what is the best model and why?\n",
    "\n",
    "**Question 6. (Possible improvements)** _(2 points)_\n",
    "* How can you improve the accuracy of your classification model?\n",
    "* How can you improve the accuracy of your regression model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a289222-6965-434a-8eaa-dd07932eaa09",
   "metadata": {},
   "source": [
    "# Q1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd4aca-e0c2-4c84-844a-52e91b93297e",
   "metadata": {},
   "source": [
    "### Relevant features impacting chance of survival:\n",
    "- Age: The \"Age\" feature is likely to be relevant as it can provide insights into the demographic characteristics of passengers. Certain age groups, such as children or the elderly, might have had different survival rates during the Titanic disaster. For example, there may have been a priority to evacuate children and older individuals, impacting the likelihood of survival.\n",
    "\n",
    "- Sex: \"Sex\" is a highly relevant feature for predicting survival. Historical data from the Titanic disaster indicates that there was a strong association between gender and survival rates. Women and children were often given priority when it came to evacuating the ship, resulting in a higher likelihood of survival for females.\n",
    "\n",
    "- AgeRange: The \"AgeRange\" feature, categorizing passengers into groups like 'Child' or 'Adult', is vital for predicting Titanic survival. It adds depth to age-related insights, reflecting how certain age groups were prioritized during evacuation. This categorical representation enhances model interpretability, simplifying the understanding of age factors impacting survival. Including \"Age Range\" accommodates historical trends, aiding the model in discerning distinct survival rates among different age groups and capturing potential non-linear relationships. In essence, \"Age Range\" is a key predictor, offering nuanced information that influences the likelihood of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8c3ac-f9c6-49f9-9b6b-1a57e9d1b692",
   "metadata": {},
   "source": [
    "### Relevant features impacting fare prediction:\n",
    "- Age: The \"Age\" feature is likely relevant as it captures the age of the passenger. Different age groups may have different travel preferences, and fares might vary based on factors associated with age. For instance, children or elderly passengers might receive discounted fares, impacting the overall fare prediction.\n",
    "\n",
    "- Pclass: Pclass\" is highly relevant as it represents the ticket class, categorizing passengers into first class (1st), second class (2nd), and third class (3rd). Ticket class is a strong indicator of socioeconomic status, and higher-class tickets are generally associated with higher fares. Including \"Pclass\" allows the model to account for variations in fare based on the level of service associated with each class.\n",
    "\n",
    "- Sibsp: The \"Sibsp\" feature, indicating the number of siblings or spouses aboard, can be relevant for fare prediction. Passengers traveling with family members may opt for different accommodations or fare packages. The presence of siblings or spouses might influence fare decisions, and including this feature enables the model to capture such variations.\n",
    "\n",
    "- Parch: Similar to \"Sibsp,\" the \"Parch\" feature, representing the number of parents or children aboard, is relevant for capturing family-related dynamics influencing fare choices. Passengers traveling with parents or children may have different fare considerations, and incorporating \"Parch\" provides insights into these familial factors impacting fare prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1eb91a3e-21c4-4a45-bf3a-42280c2b0c11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31b1da21-2e16-453e-b324-140301babfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>AgeRange</th>\n",
       "      <th>NameTitle</th>\n",
       "      <th>NewAge</th>\n",
       "      <th>NewAgeRange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Mr</td>\n",
       "      <td>22.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>38.0</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Miss</td>\n",
       "      <td>26.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>35.0</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Mr</td>\n",
       "      <td>35.0</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Rev</td>\n",
       "      <td>27.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Miss</td>\n",
       "      <td>19.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Miss</td>\n",
       "      <td>30.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Mr</td>\n",
       "      <td>26.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Mr</td>\n",
       "      <td>32.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "...               ...     ...   \n",
       "887                 0       2   \n",
       "888                 1       1   \n",
       "889                 0       3   \n",
       "890                 1       1   \n",
       "891                 0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female  30.0   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch     Fare     AgeRange NameTitle  NewAge  \\\n",
       "PassengerId                                                         \n",
       "1                1      0   7.2500  Young Adult        Mr    22.0   \n",
       "2                1      0  71.2833        Adult       Mrs    38.0   \n",
       "3                0      0   7.9250  Young Adult      Miss    26.0   \n",
       "4                1      0  53.1000        Adult       Mrs    35.0   \n",
       "5                0      0   8.0500        Adult        Mr    35.0   \n",
       "...            ...    ...      ...          ...       ...     ...   \n",
       "887              0      0  13.0000  Young Adult       Rev    27.0   \n",
       "888              0      0  30.0000  Young Adult      Miss    19.0   \n",
       "889              1      2  23.4500  Young Adult      Miss    30.0   \n",
       "890              0      0  30.0000  Young Adult        Mr    26.0   \n",
       "891              0      0   7.7500        Adult        Mr    32.0   \n",
       "\n",
       "                  NewAgeRange  \n",
       "PassengerId                    \n",
       "1            (16.336, 32.252]  \n",
       "2            (32.252, 48.168]  \n",
       "3            (16.336, 32.252]  \n",
       "4            (32.252, 48.168]  \n",
       "5            (32.252, 48.168]  \n",
       "...                       ...  \n",
       "887          (16.336, 32.252]  \n",
       "888          (16.336, 32.252]  \n",
       "889          (16.336, 32.252]  \n",
       "890          (16.336, 32.252]  \n",
       "891          (16.336, 32.252]  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the previously cleaned dataset from my first assignment into a dataframe\n",
    "\n",
    "data = pd.read_csv(\"cleaned_data.csv\")\n",
    "data.set_index(\"PassengerId\", inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0713c7b-83e1-4f3e-927d-f792ab3e2fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Converting the gender binary classification from categorical to numerical to be used and understood by the machine learning models\n",
    "\n",
    "def fun(gender): \n",
    "    if gender == \"female\":\n",
    "        return 1\n",
    "    elif gender == \"male\":\n",
    "        return 0\n",
    "    \n",
    "data[\"Sex\"] = data[\"Sex\"].apply(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b39df884-d596-4721-b735-1dbfeed71be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      0\n",
       "      ..\n",
       "887    0\n",
       "888    1\n",
       "889    1\n",
       "890    0\n",
       "891    0\n",
       "Name: Sex, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b6ca269-f86b-4dd4-8df2-26d47f7ce356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>AgeRange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch     Fare  AgeRange\n",
       "PassengerId                                                              \n",
       "1                   0       3    0  22.0      1      0   7.2500         3\n",
       "2                   1       1    1  38.0      1      0  71.2833         5\n",
       "3                   1       3    1  26.0      0      0   7.9250         3\n",
       "4                   1       1    1  35.0      1      0  53.1000         5\n",
       "5                   0       3    0  35.0      0      0   8.0500         5\n",
       "...               ...     ...  ...   ...    ...    ...      ...       ...\n",
       "887                 0       2    0  27.0      0      0  13.0000         3\n",
       "888                 1       1    1  19.0      0      0  30.0000         3\n",
       "889                 0       3    1  30.0      1      2  23.4500         3\n",
       "890                 1       1    0  26.0      0      0  30.0000         3\n",
       "891                 0       3    0  32.0      0      0   7.7500         5\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now, I will map each age category to a numerical value to be used and understood by the machine learning models and drop the columns that won't be needed for \n",
    "our classification and regression predictions.'''  \n",
    "\n",
    "data[\"AgeRange\"] = data[\"AgeRange\"].map({'Child': 1, \"Teenager\":2, \"Young Adult\": 3, \"Old Man\": 4, \"Adult\":  5})\n",
    "data = data.drop([\"Name\",\"NameTitle\", \"NewAgeRange\", \"NewAge\"], axis = 1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b2b4cff3-8b55-4374-96c6-0474b5687fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    category\n",
       "Pclass      category\n",
       "Sex         category\n",
       "Age          float64\n",
       "SibSp          int64\n",
       "Parch          int64\n",
       "Fare         float64\n",
       "AgeRange    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Converting the 'Pclass', 'Sex', 'Survived', and 'AgeRange' columns to categorical datatypes to allow the machine learning models to easily interpret and infer \n",
    "the columns' values to allow for accurate predictions.'''   \n",
    "\n",
    "data[\"Pclass\"] = pd.Categorical(data[\"Pclass\"])\n",
    "data[\"Sex\"] = pd.Categorical(data[\"Pclass\"])\n",
    "data[\"Survived\"] = pd.Categorical(data[\"Survived\"])\n",
    "data[\"AgeRange\"] = pd.Categorical(data[\"AgeRange\"])\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e714e-f0f5-4ded-a151-b23ba4525e53",
   "metadata": {},
   "source": [
    "# Q2 & 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18d1ef01-4a15-4da5-998c-ea9d12dfca77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Using the 'Sex', 'Age', and 'AgeRange' features as our predictors and the 'Survived' column as the target column that we want the model to predict.'''\n",
    "\n",
    "predictors = data.loc[:, data.columns.isin(['Sex', 'Age', 'AgeRange'])]\n",
    "target = data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "823dda20-5230-4463-bd3d-7cef6bdaff9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''For each model, we split 70% of the data to train the model and the other 30% to test the model. Also, a for loop is used to iterate through multiple random \n",
    "state values and find the one that yields the highest accuracy for each model.'''\n",
    "\n",
    "logreg_best_random_state = 0\n",
    "logreg_best_accuracy = 0\n",
    "\n",
    "random_state_values = range(1, 1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3313ae-bd81-4ad2-89d2-98ee70e09ecf",
   "metadata": {},
   "source": [
    "### Classification Machine Learning Model #1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70153d01-44f3-4bb1-bd10-42bf1cc0ab8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model's Best Random State is 258 yielding an accuracy of 0.7910447761194029\n"
     ]
    }
   ],
   "source": [
    "'''The rationale for using a Logistic Regression model is that it is a commonly used algorithm for binary classification problems, which is suitable for \n",
    "predicting outcomes with two classes (survived or not survived). It models the probability of the target class and is relatively simple and interpretable, \n",
    "making it a good starting point for classification tasks.'''\n",
    "\n",
    "for random_state in random_state_values:\n",
    "    \n",
    "    predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = random_state)\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(predictors_train, target_train)\n",
    "    logreg_prediction = logreg.predict(predictors_test)\n",
    "    logreg_current_accuracy = accuracy_score(target_test, logreg_prediction)\n",
    "    \n",
    "    if logreg_current_accuracy > logreg_best_accuracy:\n",
    "        logreg_best_accuracy = logreg_current_accuracy\n",
    "        logreg_best_random_state = random_state\n",
    "    \n",
    "print(f\"Logistic Regression Model's Best Random State is {logreg_best_random_state} yielding an accuracy of {logreg_best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bee99f02-c2aa-46b8-9657-705fa52480ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.7910447761194029\n",
      "Logistic Regression Model Area Under the Curve: 0.7536231884057971\n",
      "Logistic Regression Model Precision: 0.5714285714285714\n",
      "Logistic Regression Model Recall: 0.7376916868442291\n"
     ]
    }
   ],
   "source": [
    "'''Setting the Logistic Regression model's best random state as the split's random state + Calculating the Logistic Regression model's accuracy score, precision\n",
    "score, recall score, and area under the curve score.'''\n",
    "\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = logreg_best_random_state)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(predictors_train, target_train)\n",
    "logreg_prediction = logreg.predict(predictors_test)\n",
    "\n",
    "logreg_acc = accuracy_score(target_test, logreg_prediction, normalize = True)\n",
    "logreg_prec = precision_score(target_test, logreg_prediction)\n",
    "logreg_rec = recall_score(target_test, logreg_prediction)\n",
    "logreg_auc = metrics.roc_auc_score(target_test, logreg_prediction)\n",
    "\n",
    "print(\"Logistic Regression Model Accuracy:\", logreg_acc)\n",
    "print(\"Logistic Regression Model Area Under the Curve:\", logreg_prec)\n",
    "print(\"Logistic Regression Model Precision:\", logreg_rec)\n",
    "print(\"Logistic Regression Model Recall:\", logreg_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85c4dad2-d44c-4dac-8321-e6d7ca84d08c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under the Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.737692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Model  Accuracy Precision    Recall Area Under the Curve\n",
       "0  Logistic Regression  0.791045  0.753623  0.571429             0.737692"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the Logistic Regression model's metrics into a dataframe to improve metric visualization \n",
    "\n",
    "logreg_model_performance = pd.DataFrame([\"Logistic Regression\", logreg_acc, logreg_prec, logreg_rec, logreg_auc]).transpose()\n",
    "logreg_model_performance.columns = [\"Classification Model\", \"Accuracy\", \"Precision\", \"Recall\", \"Area Under the Curve\"]\n",
    "\n",
    "logreg_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "466061ed-fca6-4ec6-aa61-f36064b93f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_best_random_state = 0\n",
    "svm_best_accuracy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17fb03b-4bbd-4b69-a8b6-110667f02dd3",
   "metadata": {},
   "source": [
    "### Classification Machine Learning Model #2: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc894bbe-e09d-45a8-85b5-3dd06ef7e2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Model's Best Random State is 931 yielding an accuracy of 0.7574626865671642\n"
     ]
    }
   ],
   "source": [
    "'''The rationale for using a Support Vector Machine model is that it is a powerful algorithm for binary classification. It works well in high-dimensional spaces\n",
    "and is effective when there is a clear margin of separation between classes. SVM can capture complex relationships and is less sensitive to outliers. It might \n",
    "be suitable for distinguishing between passengers who survived and those who did not.'''\n",
    "\n",
    "for random_state in random_state_values:\n",
    "    \n",
    "    predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = random_state)\n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(predictors_train, target_train)\n",
    "    svm_prediction = svm.predict(predictors_test)\n",
    "    svm_current_accuracy = accuracy_score(target_test, svm_prediction)\n",
    "    \n",
    "    if svm_current_accuracy > svm_best_accuracy:\n",
    "        svm_best_accuracy = svm_current_accuracy\n",
    "        svm_best_random_state = random_state\n",
    "    \n",
    "print(f\"Support Vector Machine Model's Best Random State is {svm_best_random_state} yielding an accuracy of {svm_best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ed409938-7fe3-404f-990c-5e1d9d6074d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Model Accuracy (Post-Scaling): 0.7611940298507462\n",
      "Support Vector Machine Model Area Under the Curve (Post-Scaling): 0.7571428571428571\n",
      "Support Vector Machine Model Precision (Post-Scaling): 0.53\n",
      "Support Vector Machine Model Recall (Post-Scaling): 0.714404761904762\n"
     ]
    }
   ],
   "source": [
    "'''Setting the Support Vector Machine model's best random state as the split's random state + Calculating the Support Vector Machine model's accuracy score,\n",
    "precision score, recall score, and area under the curve score.'''\n",
    "\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = svm_best_random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "predictors_train_scaled = scaler.fit_transform(predictors_train)\n",
    "predictors_test_scaled = scaler.transform(predictors_test)\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(predictors_train_scaled, target_train)\n",
    "svm_prediction = svm.predict(predictors_test_scaled)\n",
    "\n",
    "svm_acc = accuracy_score(target_test, svm_prediction, normalize = True)\n",
    "svm_prec = precision_score(target_test, svm_prediction)\n",
    "svm_rec = recall_score(target_test, svm_prediction)\n",
    "svm_auc = metrics.roc_auc_score(target_test, svm_prediction)\n",
    "\n",
    "print(\"Support Vector Machine Model Accuracy (Post-Scaling):\", svm_acc)\n",
    "print(\"Support Vector Machine Model Area Under the Curve (Post-Scaling):\", svm_prec)\n",
    "print(\"Support Vector Machine Model Precision (Post-Scaling):\", svm_rec)\n",
    "print(\"Support Vector Machine Model Recall (Post-Scaling):\", svm_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1cea3fd5-f4e9-4227-9865-2c985b4c6ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under the Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.714405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Classification Model  Accuracy Precision Recall Area Under the Curve\n",
       "0  Support Vector Machine  0.761194  0.757143   0.53             0.714405"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the Support Vector Machine model's metrics into a dataframe to improve metric visualization \n",
    "\n",
    "svm_model_performance = pd.DataFrame([\"Support Vector Machine\", svm_acc, svm_prec, svm_rec, svm_auc]).transpose()\n",
    "svm_model_performance.columns = [\"Classification Model\", \"Accuracy\", \"Precision\", \"Recall\", \"Area Under the Curve\"]\n",
    "\n",
    "svm_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e78d6b83-19f2-4d26-ae43-eff42aec04b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_class_best_random_state = 0\n",
    "rf_class_best_accuracy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be3de6-b24d-4141-b842-e83dde85f5da",
   "metadata": {},
   "source": [
    "### Classification Machine Learning Model #3: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36cef3b5-5f8d-495d-a511-9e6852d62352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Model's Best Random State is 266 yielding an accuracy of 0.7425373134328358\n"
     ]
    }
   ],
   "source": [
    "'''Random Forest is an ensemble learning method that can handle both classification and regression tasks. It's robust, handles non-linear relationships well,\n",
    "and is less prone to overfitting. Random Forest is a good choice for the Titanic dataset as it can capture complex interactions between features and handle \n",
    "missing values effectively.'''\n",
    "\n",
    "for random_state in random_state_values:\n",
    "    \n",
    "    predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = random_state)\n",
    "    rf_class = RandomForestClassifier()\n",
    "    rf_class.fit(predictors_train, target_train)\n",
    "    rf_class_prediction = rf_class.predict(predictors_test)\n",
    "    rf_class_current_accuracy = accuracy_score(target_test, rf_class_prediction)\n",
    "    \n",
    "    if rf_class_current_accuracy > rf_class_best_accuracy:\n",
    "        rf_class_best_accuracy = rf_class_current_accuracy\n",
    "        rf_class_best_random_state = random_state\n",
    "    \n",
    "print(f\"Random Forest Classifier Model's Best Random State is {rf_class_best_random_state} yielding an accuracy of {rf_class_best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "104459a4-f925-4941-a3bd-5af302ec14ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Model Accuracy: 0.7388059701492538\n",
      "Random Forest Classifier Model Area Under the Curve: 0.6835443037974683\n",
      "Random Forest Classifier Model Precision: 0.5454545454545454\n",
      "Random Forest Classifier Model Recall: 0.7162751778136391\n"
     ]
    }
   ],
   "source": [
    "'''Setting the Random Forest Classifier model's best random state as the split's random state + Calculating the Random Forest Classifier model's accuracy score,\n",
    "precision score, recall score, and area under the curve score'''\n",
    "\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = rf_class_best_random_state)\n",
    "rf_class = RandomForestClassifier(random_state = rf_class_best_random_state)\n",
    "rf_class.fit(predictors_train, target_train)\n",
    "rf_class_prediction = rf_class.predict(predictors_test)\n",
    "rf_class_probabilities = rf_class.predict_proba(predictors_test)[:, 1]\n",
    "\n",
    "rf_class_acc = accuracy_score(target_test, rf_class_prediction, normalize = True)\n",
    "rf_class_prec = precision_score(target_test, rf_class_prediction)\n",
    "rf_class_rec = recall_score(target_test, rf_class_prediction)\n",
    "rf_class_auc = metrics.roc_auc_score(target_test, rf_class_probabilities)\n",
    "\n",
    "print(\"Random Forest Classifier Model Accuracy:\", rf_class_acc)\n",
    "print(\"Random Forest Classifier Model Area Under the Curve:\", rf_class_prec)\n",
    "print(\"Random Forest Classifier Model Precision:\", rf_class_rec)\n",
    "print(\"Random Forest Classifier Model Recall:\", rf_class_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e47f6-0e13-4b4d-bc99-4e54ea9d4287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under the Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.716275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classification Model  Accuracy Precision    Recall Area Under the Curve\n",
       "0  Random Forest Classifier  0.738806  0.683544  0.545455             0.716275"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the Random Forest Classifier model's metrics into a dataframe to improve metric visualization \n",
    "\n",
    "rf_class_model_performance = pd.DataFrame([\"Random Forest Classifier\", rf_class_acc, rf_class_prec, rf_class_rec, rf_class_auc]).transpose()\n",
    "rf_class_model_performance.columns = [\"Classification Model\", \"Accuracy\", \"Precision\", \"Recall\", \"Area Under the Curve\"]\n",
    "\n",
    "rf_class_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f0ce0-7a4f-4145-9b5f-6d2b5e986a71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under the Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.737692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.714405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.716275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classification Model  Accuracy Precision    Recall Area Under the Curve\n",
       "0       Logistic Regression  0.791045  0.753623  0.571429             0.737692\n",
       "1    Support Vector Machine  0.761194  0.757143      0.53             0.714405\n",
       "2  Random Forest Classifier  0.738806  0.683544  0.545455             0.716275"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concating all classification models and their metrics into a single dataframe to evaluate each model's performance\n",
    "\n",
    "df_class_models = pd.concat([logreg_model_performance, svm_model_performance, rf_class_model_performance], axis=0)\n",
    "df_class_models.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e0dc1-0f05-4f25-a5c3-54c055c9f575",
   "metadata": {},
   "source": [
    "### Evaluation of Classification Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373d738-f3ee-42c7-9858-a8f2a7e6bd5c",
   "metadata": {},
   "source": [
    "**Upon scrutinizing the evaluation metrics of three classification models—Logistic Regression, Support Vector Machine (SVM), and Random Forest Classifier—a clear pattern emerges, suggesting the Logistic Regression model as the optimal choice for this particular task. With an accuracy of 0.7910, Logistic Regression outperforms both SVM (0.7612) and Random Forest (0.7388), indicating a higher proportion of correctly classified instances. Moreover, Logistic Regression achieves a notable recall of 0.5714 and precision of 0.7536, striking a balance between accurately identifying positive instances and capturing true positives. While SVM and Random Forest present competitive performances, Logistic Regression's comprehensive excellence across multiple metrics positions it as the preferred model. The area under the curve (AUC) for Logistic Regression, at 0.7377, underscores its ability to discriminate between positive and negative instances. In summary, the Logistic Regression model stands out as the best choice, showcasing a harmonious blend of accuracy, precision, and recall for this classification task.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09271fc5-f819-4434-bca6-d5cc8b214d2a",
   "metadata": {},
   "source": [
    "# Q4 & 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4d58656e-9727-4dd5-beed-c75400a7369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Using the 'Age', 'SibSp', 'Parch', and 'Pclass' features as our predictors and the 'Fare' column as the target column that we want the model to predict.'''\n",
    "\n",
    "predictors = data.loc[:, data.columns.isin(['Age', 'SibSp', 'Parch', 'Pclass'])]\n",
    "target = data[\"Fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "627a86c6-5305-48db-ac88-9d7326fc9f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''For each model, we split 70% of the data to train the model and the other 30% to test the model. Also, a for loop is used to iterate through multiple random \n",
    "state values and find the one that yields the highest r2 score for each model.'''\n",
    "\n",
    "linreg_best_random_state = 0\n",
    "linreg_best_r2_score = 0\n",
    "\n",
    "random_state_values = range(1, 1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba87fda8-17a2-4155-9e28-50d2877f2d05",
   "metadata": {},
   "source": [
    "### Regression Machine Learning Model #1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "27972347-ba01-41cc-89d1-395629ebbd75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model's Best Random State is 93 yielding an r2 score of 0.5442760520461438\n"
     ]
    }
   ],
   "source": [
    "'''The rationale for using a Linear Regression model is that it is a simple and interpretable algorithm for predicting numeric values, making it a good choice\n",
    "for regression problems. It assumes a linear relationship between the input features and the target variable, which might be appropriate for predicting the fare\n",
    "based on relevant features of a passenger.'''\n",
    "\n",
    "for random_state in random_state_values:\n",
    "    \n",
    "    predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = random_state)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(predictors_train, target_train)\n",
    "    linreg_prediction = linreg.predict(predictors_test)\n",
    "    linreg_current_r2_score = r2_score(target_test, linreg_prediction)\n",
    "    \n",
    "    if linreg_current_r2_score > linreg_best_r2_score:\n",
    "        linreg_best_r2_score = linreg_current_r2_score\n",
    "        linreg_best_random_state = random_state\n",
    "    \n",
    "print(f\"Linear Regression Model's Best Random State is {linreg_best_random_state} yielding an r2 score of {linreg_best_r2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "094b8a36-59a5-494c-8de1-ea364a4bcd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Mean Absolute Error: 16.223368097299595\n",
      "Linear Regression Model Mean Squared Error: 644.0634782783485\n",
      "Linear Regression Model R-Squared Score: 0.5442760520461438\n"
     ]
    }
   ],
   "source": [
    "'''Setting the Linear Regression model's best random state as the split's random state + Calculating the Linear Regression model's mean absolute error,\n",
    "mean squared error, and r-squared score'''\n",
    "\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = linreg_best_random_state)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(predictors_train, target_train)\n",
    "linreg_prediction = linreg.predict(predictors_test)\n",
    "\n",
    "linreg_mae = mean_absolute_error(target_test, linreg_prediction)\n",
    "linreg_mse = mean_squared_error(target_test, linreg_prediction)\n",
    "linreg_r2 = r2_score(target_test, linreg_prediction)\n",
    "\n",
    "print(\"Linear Regression Model Mean Absolute Error:\", linreg_mae)\n",
    "print(\"Linear Regression Model Mean Squared Error:\", linreg_mse)\n",
    "print(\"Linear Regression Model R-Squared Score:\", linreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "10c8dcef-4c51-415e-b8b4-e73f4d7204f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regression Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>R-Squared Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>16.223368</td>\n",
       "      <td>644.063478</td>\n",
       "      <td>0.544276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Regression Model Mean Absolute Error Mean Squared Error R-Squared Score\n",
       "0  Linear Regression           16.223368         644.063478        0.544276"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the Random Forest Classifier model's metrics into a dataframe to improve metric visualization \n",
    "\n",
    "linreg_model_performance = pd.DataFrame([\"Linear Regression\", linreg_mae, linreg_mse, linreg_r2]).transpose()\n",
    "linreg_model_performance.columns = [\"Regression Model\", \"Mean Absolute Error\", \"Mean Squared Error\", \"R-Squared Score\"]\n",
    "\n",
    "linreg_model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fa0cb-d8f0-40e8-ae35-77917c2aaf3a",
   "metadata": {},
   "source": [
    "### Regression Machine Learning Model #2: Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9b1f5b83-3f11-4a63-9426-1c4e9b45c451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gradboost_best_random_state = 0\n",
    "gradboost_best_r2_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8ff66f71-164f-49b2-9232-795410182b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Model's Best Random State is 614 yielding an r2 score of 0.7426767513693191\n"
     ]
    }
   ],
   "source": [
    "'''The Gradient Boosting Regressor is chosen for predicting passenger fares due to its ability to capture complex non-linear relationships, robustness to \n",
    "outliers, and versatility in handling various data types. As an ensemble method, it sequentially builds weak learners, providing improved predictive performance.\n",
    "Its feature importance analysis aids in understanding influential factors, and fine-tuning options enhance adaptability to specific dataset characteristics.'''\n",
    "\n",
    "for random_state in random_state_values:\n",
    "    \n",
    "    predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = random_state)\n",
    "    gradboost = GradientBoostingRegressor()\n",
    "    gradboost.fit(predictors_train, target_train)\n",
    "    gradboost_prediction = gradboost.predict(predictors_test)\n",
    "    gradboost_current_r2_score = r2_score(target_test, gradboost_prediction)\n",
    "    \n",
    "    if gradboost_current_r2_score > gradboost_best_r2_score:\n",
    "        gradboost_best_r2_score = gradboost_current_r2_score\n",
    "        gradboost_best_random_state = random_state\n",
    "    \n",
    "print(f\"Gradient Boosting Regressor Model's Best Random State is {gradboost_best_random_state} yielding an r2 score of {gradboost_best_r2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "69ff2ba3-b388-4916-a74a-fbb1f4f9c29c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Model Mean Absolute Error: 10.822064053918915\n",
      "Gradient Boosting Regressor Model Mean Squared Error: 489.3183983110392\n",
      "Gradient Boosting Regressor Model R-Squared Score: 0.7427004428938411\n"
     ]
    }
   ],
   "source": [
    "'''Setting the Gradient Boosting Regressor model's best random state as the split's random state + Calculating the Gradient Boosting Regressor model's mean \n",
    "absolute error, mean squared error, and r-squared score'''\n",
    "\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = gradboost_best_random_state)\n",
    "gradboost = GradientBoostingRegressor()\n",
    "gradboost.fit(predictors_train, target_train)\n",
    "gradboost_prediction = gradboost.predict(predictors_test)\n",
    "\n",
    "gradboost_mae = mean_absolute_error(target_test, gradboost_prediction)\n",
    "gradboost_mse = mean_squared_error(target_test, gradboost_prediction)\n",
    "gradboost_r2 = r2_score(target_test, gradboost_prediction)\n",
    "\n",
    "print(\"Gradient Boosting Regressor Model Mean Absolute Error:\", gradboost_mae)\n",
    "print(\"Gradient Boosting Regressor Model Mean Squared Error:\", gradboost_mse)\n",
    "print(\"Gradient Boosting Regressor Model R-Squared Score:\", gradboost_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6f478fd7-e749-49ea-95bc-0a4559b03372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regression Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>R-Squared Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>10.822064</td>\n",
       "      <td>489.318398</td>\n",
       "      <td>0.7427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Regression Model Mean Absolute Error Mean Squared Error  \\\n",
       "0  Gradient Boosting Regressor           10.822064         489.318398   \n",
       "\n",
       "  R-Squared Score  \n",
       "0          0.7427  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the Random Forest Classifier model's metrics into a dataframe to improve metric visualization \n",
    "\n",
    "gradboost_model_performance = pd.DataFrame([\"Gradient Boosting Regressor\", gradboost_mae, gradboost_mse, gradboost_r2]).transpose()\n",
    "gradboost_model_performance.columns = [\"Regression Model\", \"Mean Absolute Error\", \"Mean Squared Error\", \"R-Squared Score\"]\n",
    "\n",
    "gradboost_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7b9c5ad2-c6ca-41a6-9c48-e188cff9a3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regression Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>R-Squared Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>16.223368</td>\n",
       "      <td>644.063478</td>\n",
       "      <td>0.544276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>10.822064</td>\n",
       "      <td>489.318398</td>\n",
       "      <td>0.7427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Regression Model Mean Absolute Error Mean Squared Error  \\\n",
       "0            Linear Regression           16.223368         644.063478   \n",
       "1  Gradient Boosting Regressor           10.822064         489.318398   \n",
       "\n",
       "  R-Squared Score  \n",
       "0        0.544276  \n",
       "1          0.7427  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concating all regression models and their metrics into a single dataframe to evaluate each model's performance\n",
    "\n",
    "df_reg_models = pd.concat([linreg_model_performance, gradboost_model_performance], axis=0)\n",
    "df_reg_models.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf73d58-2905-4d57-afd5-4602deff0e30",
   "metadata": {},
   "source": [
    "### Evaluation of Regression Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b345ee6-9e68-4daf-811a-fe8f17942e69",
   "metadata": {},
   "source": [
    "**The Gradient Boosting Regressor emerges as the superior model based on comprehensive evaluation metrics. With a lower Mean Absolute Error (MAE) of 10.82 compared to the Linear Regression model's 16.22, the Gradient Boosting Regressor consistently provides predictions that are closer to the actual values. Additionally, the Gradient Boosting model exhibits a lower Mean Squared Error (MSE) of 489.32, highlighting its superior performance in minimizing squared prediction errors. The R-Squared score further supports its excellence, standing at 0.74 compared to the Linear Regression model's 0.54. This higher R-Squared score indicates that the Gradient Boosting Regressor explains a larger proportion of the variance in the target variable. Collectively, these metrics underscore the superior accuracy and precision of the Gradient Boosting Regressor, establishing it as the preferred model for the regression task.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1dedb-a5cf-4cfe-b2bc-0fe595619499",
   "metadata": {},
   "source": [
    "# Q6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd90c3e-5a04-4217-ae05-752ab13b9390",
   "metadata": {},
   "source": [
    "### Improving Classification Model Accuracy (Logistic Regression):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0557b-16d2-451d-9043-8177d705c278",
   "metadata": {},
   "source": [
    "- Handling Outliers: Evaluate and handle outliers in the dataset that might be influencing the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6885adcb-3959-48d0-bf0a-d33c3bfad737",
   "metadata": {},
   "source": [
    "- Feature Scaling: Ensure that features are scaled appropriately, especially if the logistic regression model is sensitive to feature magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd048bec-92c1-4d11-adf6-1f8062c19f54",
   "metadata": {},
   "source": [
    "- Feature Importance Analysis: Use feature importance analysis to focus on the most influential features and potentially eliminate less important ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb1851-b283-4cd0-b24d-9ab338bfe553",
   "metadata": {},
   "source": [
    "- Addressing Class Imbalance: Utilizing techniques such as oversampling the minority class or undersampling the majority class to address dataset imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac8ebf-9ca3-498f-905d-692dfc3bce91",
   "metadata": {},
   "source": [
    "### Improving Regression Model Accuracy (Gradient Boosting Regressor):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1629e2-d7f8-44be-a9cb-802360a2229b",
   "metadata": {},
   "source": [
    "- Hyperparameter Tuning: Experiment with different values for hyperparameters like the number of estimators, learning rate, and the maximum depth of each tree to find the optimal configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89facb9a-145e-41af-8315-9cb7b31dff4c",
   "metadata": {},
   "source": [
    "- Feature Engineering: Identify and create additional relevant features that can improve the model's ability to capture underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e197e-4766-42d7-b0e5-df2b8307cad5",
   "metadata": {},
   "source": [
    "- Cross-Validation: Employ cross-validation to assess how well the model generalizes to new data and to identify potential issues like overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d3751-c029-43b9-b2b6-eac4a3091c87",
   "metadata": {},
   "source": [
    "- Early Stopping: Implement early stopping to halt training once the model performance stops improving on a validation set. This prevents overfitting."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
